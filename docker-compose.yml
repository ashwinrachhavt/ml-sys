version: "3.9"

services:
  api:
    build:
      context: .
      dockerfile: Dockerfile
    image: mlsys-serve:latest
    ports:
      - "8000:8000"
    environment:
      MLSYS_TRACKING__TRACKING_URI: http://mlflow:5000
      MLSYS_SERVING__LOCAL_MODEL_PATH: models/best.joblib
    volumes:
      - ./config:/app/config:ro
      # Provide dataset under project root for resolution
      - ./config/dataset:/app/dataset:ro
      - ./mlflow:/app/mlruns
      - ./models:/app/models
    depends_on:
      - mlflow

  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.9.2
    command: >
      mlflow server
      --backend-store-uri sqlite:///mlruns/mlflow.db
      --default-artifact-root /mlruns/artifacts
      --host 0.0.0.0
      --port 5000
    ports:
      - "5000:5000"
    volumes:
      - ./mlflow:/mlruns

  trainer:
    build:
      context: .
      dockerfile: Dockerfile
    image: mlsys-train:latest
    command: python scripts/train.py
    environment:
      MLSYS_TRACKING__TRACKING_URI: http://mlflow:5000
      MLSYS_SERVING__LOCAL_MODEL_PATH: models/best.joblib
    volumes:
      - ./config:/app/config:ro
      - ./config/dataset:/app/dataset:ro
      - ./mlflow:/app/mlruns
      - ./models:/app/models

  evaluate:
    build:
      context: .
      dockerfile: Dockerfile
    image: mlsys-evaluate:latest
    command: python scripts/evaluate.py
    environment:
      MLSYS_TRACKING__TRACKING_URI: http://mlflow:5000
      MLSYS_SERVING__LOCAL_MODEL_PATH: models/best.joblib
    volumes:
      - ./config:/app/config:ro
      - ./config/dataset:/app/dataset:ro
      - ./mlflow:/app/mlruns
      - ./models:/app/models
    depends_on:
      - mlflow
